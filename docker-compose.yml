version: '3.8'

services:
  data-ingest:
    build: .
    image: hive-parquet-ingest:latest
    container_name: data-ingest
    restart: unless-stopped
    
    # Example for file input
    # command: ["--input", "/input/data.txt", "--source", "mydata"]
    # volumes:
    #   - ./input:/input:ro
    #   - ./output:/data
    
    # Example for WebSocket AIS Stream input with S3 upload
    command: [
      "--ws-url", "wss://stream.aisstream.io/v0/stream",
      "--ws-api-key", "${AIS_API_KEY}",
      "--ws-bbox", "37.9,-122.6,37.6,-122.3",
      "--source", "ais-sf-bay",
      "--s3-bucket", "maritime-data",
      "--s3-region", "us-west-2"
    ]
    
    # Alternative: TCP input
    # command: [
    #   "--tcp-host", "153.44.253.27", 
    #   "--tcp-port", "5631",
    #   "--source", "norway-tcp",
    #   "--s3-bucket", "my-data-bucket",
    #   "--s3-region", "us-west-2"
    # ]
    volumes:
      - ./output:/data
    
    # Health check configuration
    healthcheck:
      test: ["/usr/local/bin/hive_parquet_ingest", "--health-check"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    
    # Environment variables
    environment:
      - RUST_LOG=info
      - AIS_API_KEY=${AIS_API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    
    # Network configuration (if needed)
    # networks:
    #   - data-network

# Uncomment if you need custom networks
# networks:
#   data-network:
#     driver: bridge